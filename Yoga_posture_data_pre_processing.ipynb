{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "XTwh8DLfXTNO",
        "outputId": "02b00f1b-0294-4094-c7d5-b13d8f7bb324"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Users/melitamadhurza/Desktop/AIT_Deep_Learning/Dataset/TRAIN'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-fff1cb98f77d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# Loop through each subfolder (each subfolder represents a class)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/melitamadhurza/Desktop/AIT_Deep_Learning/Dataset/TRAIN'"
          ]
        }
      ],
      "source": [
        "#%% [markdown]\n",
        "# # Image Augmentation\n",
        "#\n",
        "# In this first section, we define functions to augment images.\n",
        "# The augmentation techniques include random rotation, horizontal flip, random cropping, brightness and contrast adjustments, and scaling.\n",
        "#\n",
        "# After running these cells, we can generate augmented images which will be saved into a new folder.\n",
        "\n",
        "#%% [code]\n",
        "import os\n",
        "import random\n",
        "from PIL import Image, ImageEnhance\n",
        "\n",
        "def augment_image(image):\n",
        "    # random rotation between -15 and 15 degrees\n",
        "    angle = random.randint(-15, 15)\n",
        "    image = image.rotate(angle, expand=True)\n",
        "\n",
        "    # horizontal flip\n",
        "    if random.random() > 0.5:\n",
        "        image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "    # random cropping\n",
        "    width, height = image.size\n",
        "    new_width = int(width * random.uniform(0.8, 1.0))  # Crop width between 80% and 100%\n",
        "    new_height = int(height * random.uniform(0.8, 1.0))  # Crop height between 80% and 100%\n",
        "\n",
        "    # random position for cropping\n",
        "    left = random.randint(0, width - new_width)\n",
        "    top = random.randint(0, height - new_height)\n",
        "    right = left + new_width\n",
        "    bottom = top + new_height\n",
        "\n",
        "    image = image.crop((left, top, right, bottom))\n",
        "\n",
        "    # random brightness\n",
        "    enhancer = ImageEnhance.Brightness(image)\n",
        "    image = enhancer.enhance(random.uniform(0.5, 1.5))\n",
        "\n",
        "    # contrast adjustment\n",
        "    contrast_factors = [0.8, 1.0, 1.2]  # Lower, Normal, Higher\n",
        "    contrast_factor = random.choice(contrast_factors)\n",
        "    image = ImageEnhance.Contrast(image).enhance(contrast_factor)\n",
        "\n",
        "    # scaling\n",
        "    scale_factors = [0.8, 1.0, 1.2]  # Smaller, Normal, Larger\n",
        "    scale_factor = random.choice(scale_factors)\n",
        "    new_size = (int(image.width * scale_factor), int(image.height * scale_factor))\n",
        "    image = image.resize(new_size, Image.ANTIALIAS)\n",
        "\n",
        "    return image\n",
        "\n",
        "def save_augmented_images(folder_path, output_folder, num_augmented_images=5):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    images = [f for f in os.listdir(folder_path) if f.lower().endswith('.jpg')]\n",
        "\n",
        "    for img_name in images:\n",
        "        img_path = os.path.join(folder_path, img_name)\n",
        "        img = Image.open(img_path)\n",
        "        for i in range(num_augmented_images):\n",
        "            augmented_img = augment_image(img)\n",
        "            augmented_img_name = f\"{os.path.splitext(img_name)[0]}_augmented_{i}.jpg\"\n",
        "            augmented_img.save(os.path.join(output_folder, augmented_img_name))\n",
        "\n",
        "#%% [markdown]\n",
        "# **Example usage:**\n",
        "#\n",
        "# Uncomment and modify the following lines if you want to generate augmented images.\n",
        "#\n",
        "# ```python\n",
        "# folder_path = 'DATASET/TRAIN/downdog'  # Path to the folder with original images\n",
        "# output_folder = 'DATASET/TRAIN/downdog2'  # Path to save augmented images\n",
        "# save_augmented_images(folder_path, output_folder, num_augmented_images=2)\n",
        "# ```\n",
        "\n",
        "#%% [markdown]\n",
        "# # Data Preprocessing for Deep Learning\n",
        "#\n",
        "# This section loads the (augmented) images from your dataset, preprocesses them by resizing and normalizing, and produces:\n",
        "# - **X**: the input matrix (images as numerical arrays)\n",
        "# - **Y**: the output matrix (integer labels for each image)\n",
        "#\n",
        "# Optionally, we also provide one-hot encoded labels.\n",
        "\n",
        "#%% [code]\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Define the target image size (height, width)\n",
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "# Path to your dataset folder (modify as needed)\n",
        "dataset_path = '/Users/melitamadhurza/Desktop/AIT_Deep_Learning/Dataset/TRAIN'\n",
        "\n",
        "\n",
        "# Initialize lists to hold the image data and labels\n",
        "X = []\n",
        "Y = []\n",
        "class_names = []\n",
        "\n",
        "# Loop through each subfolder (each subfolder represents a class)\n",
        "for idx, folder in enumerate(sorted(os.listdir(dataset_path))):\n",
        "    folder_path = os.path.join(dataset_path, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        print(f\"Processing class '{folder}' with label {idx}\")\n",
        "        class_names.append(folder)\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.lower().endswith('.jpg'):\n",
        "                file_path = os.path.join(folder_path, filename)\n",
        "                try:\n",
        "                    # Open image, convert to RGB, and resize\n",
        "                    img = Image.open(file_path).convert('RGB')\n",
        "                    img = img.resize(IMG_SIZE)\n",
        "\n",
        "                    # Convert image to numpy array and normalize pixel values to [0, 1]\n",
        "                    img_array = np.array(img) / 255.0\n",
        "                    X.append(img_array)\n",
        "\n",
        "                    # Append label corresponding to the class index\n",
        "                    Y.append(idx)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "print(\"Shape of X (inputs):\", X.shape)  # Expected: (number_of_images, 128, 128, 3)\n",
        "print(\"Shape of Y (labels):\", Y.shape)  # Expected: (number_of_images,)\n",
        "\n",
        "#%% [markdown]\n",
        "# Optionally, if you need the labels in one-hot encoding (e.g., for a classification network), use the following cell.\n",
        "\n",
        "#%% [code]\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert labels to one-hot encoded format\n",
        "Y_onehot = to_categorical(Y, num_classes=len(class_names))\n",
        "print(\"Shape of Y (one-hot encoded):\", Y_onehot.shape)\n",
        "\n",
        "#%% [markdown]\n",
        "# Finally, save the matrices to disk for later use if desired.\n",
        "\n",
        "#%% [code]\n",
        "np.save('X.npy', X)\n",
        "np.save('Y.npy', Y)\n",
        "np.save('Y_onehot.npy', Y_onehot)\n",
        "\n",
        "print(\"Data matrices saved successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}